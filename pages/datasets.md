A group of datasets has being compiled for the purpose of this challenge. The datasets come from a few different instruments: SPHERE (both IRDIS and IFS), GPI, NIRC2 and LMIRCam. This is to ensure the challenge library contains a diverse set of datasets coming from instruments with different characteristics: slow/high speed cameras, broadband/filtered sequences, small/large total rotation, presence of a coronagraph, etc. 

In order to reduce the need of domain knowledge (e.g. the expertize related to high-contrast imaing or to a specific instrument), the datasets wereÂ calibrated/pre-processed using the standard pipelines of each instrument. Then we applied a few pre-processing procedures on each cube to make sure that the library is homogeneous. The characteristics of each dataset and the pre-processing procedures applied to them are recorded on a public [Google spreadsheet](https://docs.google.com/spreadsheets/d/1Zx7tTGNBMhCXpAa5KIoufdvMrxtjfA3q2gX03APMkaM/edit?usp=sharing). 

Please keep in mind that we use these contributed datasets to inject synthetic companions and create the data challenge library. Once the data challenge is finished, the datasets without synthetic companions will constitute the benchmark HCI library.

<iframe width="700" height="550" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vRtS1LYA97Rbv27P9T3bD3ctrS0-cxhJ9n2CT_qEIZZ-6bvwzx7u7OSaH5o9fdWIKNDnXa99b0vjalw/pubhtml?widget=true&amp;headers=false"></iframe>

For the sub-challenge on ADI post-processing, each dataset will be composed of:
 * ``instrument_cube_id.fits`` (3d array),
 * ``instrument_pa_id.fits`` (1d array, vector of parallactic angles),
 * ``instrument_pxscale_id.fits`` (float value, the pixel scale value in arc/px),
 * ``instrument_psf_id.fits`` (2d array, the associated PSF template), 
 
where id is a positive integer and instrument is one of the following: ``nirc2``, ``lmircam`` or ``sphere_irdis``. For the second sub-challenge, on spectrally dispersed data (instruments: ``sphere_ifs`` or ``gpi``), a 4D cube will be provided along with a vector of wavelengths (``instrument_wls_id.fits``). 

The cubes will be cropped to focus on the innermost 20 lambda/D. The challenge files are saved as [FITS](https://en.wikipedia.org/wiki/FITS) files, a format with long tradition in astronomy. FITS files can be easily opened in any programming language or environment (Python, Matlab, IDL, R, C, etc). The most convenient software for quick visualization of the cubes is the SAOImageDS9 viewer which can be downloaded [here](http://ds9.si.edu/site/Download.html). If you are into Python and you use Jupyterlab, then consider using the [HCIplot](https://github.com/carlgogo/hciplot/) open source library for visualizing the cubes. 

It is mandatory that the submitted datasets remain *secret* for the duration of the challenge. After the data challenge is finished, the contributed datasets (without injected companions) will constitute the **HCI benchmark library** that will be made available for the community. This benchmark library will be stored on Zenodo, ensuring the long term preservation of data, and will serve the next generation of researchers who will be able to re-use the benchmark datasets for quick validation of novel algorithms.


